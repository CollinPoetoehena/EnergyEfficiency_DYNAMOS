{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04e0695",
   "metadata": {},
   "source": [
    "# Using the Energy Efficiency Report Pipeline in FABRIC\n",
    "\n",
    "IMPORTANT: this is an additional approach that can be taken for the energy efficiency report pipeline. However, see energy-efficiency/README.md for an explanation on a better and recommended approach with an SSH tunnel on your local machine to the Prometheus deployment on the FABRIC node. This way, you can follow the same steps as you would locally, with Prometheus accessible from the local machine at localhost:9090, in this case tunneling to the Prometheus deployment on the FABRIC node.\n",
    "\n",
    "This is a short notebook that explains how to execute the energy efficiency pipeline created in this project. Make sure to follow this after the steps of the [Experiments](./experiments.ipynb) notebook have been followed, since this notebook reuses some of those things.\n",
    "\n",
    "1. The only difference is the Prometheus URL that should be queried. So, copy all the files in the energy-efficiency/data-collection folder in the FABRIC Jupyter Hub environment (for example in a separate folder to separate it from the other files). Upload them all in the same folder.\n",
    "\n",
    "2. Then replace the PROMETHEUS_URL in the constants.py file in energy-efficiency/data-collection folder with the PROMETHEUS_URL from the constants.py file in fabric/experiments (this folder). This ensures the correct Prometheus URL is used to collect the data. For example:\n",
    "\n",
    "PROMETHEUS_URL = 'http://10.145.1.5:32471'\n",
    "\n",
    "Note: no need to port-forward Prometheus on the node, this uses the NodePort that Prometheus is exposed on directly. If a port-forward is executed (kubectl port-forward svc/prometheus-kube-prometheus-prometheus -n monitoring 9090:9090), it will still work, however, it is not necessary in this case.\n",
    "\n",
    "3. Execute the below code to run the data collection.\n",
    "\n",
    "4. Finally, place the collected data file in the energy-efficiency/data-collection/data folder and execute the data-analysis file as normal on your local machine. This is because the only difference is the data collection, once the data is collected, it can be analyzed on the local machine without needing FABRIC. See the README.md in the energy-efficiency folder for instructions on how to execute the data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================== Import FABRIC library and other required libraries ======================================== \n",
    "import json\n",
    "import traceback\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "\n",
    "fablib.show_config();\n",
    "\n",
    "# ======================================== Set variables ======================================== \n",
    "slice_name = 'DYNAMOS_EnergyEfficiency'\n",
    "# Nodes:\n",
    "node1_name = 'k8s-control-plane'\n",
    "node2_name = 'dynamos-core'\n",
    "node3_name = 'vu'\n",
    "node4_name = 'uva'\n",
    "node5_name = 'surf'\n",
    "\n",
    "# ======================================== Save experiments data ======================================== \n",
    "# This separate cell can be used to extract the file \n",
    "try:\n",
    "    # Get slice by name: https://fabric-fablib.readthedocs.io/en/latest/fablib.html#fabrictestbed_extensions.fablib.fablib.FablibManager.get_slice\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "    # Get the correct node to run the experiment on (must be the same node as the experiments.ipynb notebook)\n",
    "    node = slice.get_node(name=node1_name)\n",
    "\n",
    "    # Make sure the directory exists:\n",
    "    node.execute(\"mkdir -p ~/energy-pipeline\")\n",
    "\n",
    "    # Upload required files for the experiments:\n",
    "    node.upload_file(local_file_path=\"constants.py\", remote_file_path=\"./energy-pipeline/constants.py\")\n",
    "    node.upload_file(local_file_path=\"get_metrics.py\", remote_file_path=\"./energy-pipeline/get_metrics.py\")\n",
    "    node.upload_file(local_file_path=\"query_prometheus.py\", remote_file_path=\"./energy-pipeline/query_prometheus.py\")\n",
    "    node.upload_file(local_file_path=\"utils.py\", remote_file_path=\"./energy-pipeline/utils.py\")\n",
    "    \n",
    "    # Run the experiment. This needs to run the python script to allow the output to be added in the notebook output, with a separate script that did not happen\n",
    "    # Reuse the virtual python environment created in the experiments.ipynb\n",
    "    stdout, stderr = node.execute(\n",
    "        (\n",
    "            # Make the script executable and \n",
    "            f\"chmod +x ./energy-pipeline/get_metrics.py && \"\n",
    "            # Go to the corresponding location for the venv\n",
    "            f\"cd ~/experiments && \"\n",
    "            # Activate the venv\n",
    "            f\"source dynamos-env/bin/activate && \"\n",
    "            # Install additional requirements\n",
    "            f\"pip install pandas && \"\n",
    "            # Then go to the location where the data-collection files are\n",
    "            f\"cd ~/energy-pipeline && \"\n",
    "            # Execute the actual experiments. Use -u to use unbuffered mode for stdout, stderr, and stdin, \n",
    "            # so that print() calls and logs from inside the python script appear live (or at least flush immediately after each action)\n",
    "            f\"python3 -u get_metrics.py\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Download the data file from the node to the Jupyter Notebook environment.\n",
    "    # This will now save it to the current path, from which you can manually download it and add it in the project.\n",
    "    # https://fabric-fablib.readthedocs.io/en/latest/node.html#fabrictestbed_extensions.fablib.node.Node.download_file\n",
    "    node.download_file(remote_file_path=\"./energy-pipeline/data/energy_metrics.csv\", local_file_path=\"./energy_metrics.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Fail: {e}\")\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
